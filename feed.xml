<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://lic-deep.github.io/testcolabblog2/feed.xml" rel="self" type="application/atom+xml" /><link href="https://lic-deep.github.io/testcolabblog2/" rel="alternate" type="text/html" /><updated>2021-07-04T05:29:59-05:00</updated><id>https://lic-deep.github.io/testcolabblog2/feed.xml</id><title type="html">hollo world!</title><subtitle>An easy to use blogging platform with support for Jupyter Notebooks.</subtitle><entry><title type="html">딥러닝 포스팅</title><link href="https://lic-deep.github.io/testcolabblog2/deep%20learning/2021/07/04/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4_%ED%85%8C%EC%8A%A4%ED%8A%B8.html" rel="alternate" type="text/html" title="딥러닝 포스팅" /><published>2021-07-04T00:00:00-05:00</published><updated>2021-07-04T00:00:00-05:00</updated><id>https://lic-deep.github.io/testcolabblog2/deep%20learning/2021/07/04/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4_%ED%85%8C%EC%8A%A4%ED%8A%B8</id><author><name></name></author><category term="deep learning" /><summary type="html">Example Markdown Post</summary></entry><entry><title type="html">51561</title><link href="https://lic-deep.github.io/testcolabblog2/2020/07/04/51561.ipynb" rel="alternate" type="text/html" title="51561" /><published>2020-07-04T00:00:00-05:00</published><updated>2020-07-04T00:00:00-05:00</updated><id>https://lic-deep.github.io/testcolabblog2/2020/07/04/%2051561</id><author><name></name></author><summary type="html">{ &quot;cells&quot;: [ { &quot;cell_type&quot;: &quot;code&quot;, &quot;execution_count&quot;: null, &quot;id&quot;: &quot;4ce10ae1&quot;, &quot;metadata&quot;: {}, &quot;outputs&quot;: [], &quot;source&quot;: [ &quot;# \&quot;제목 !!\&quot;\n&quot;, &quot;&gt; \&quot;요약!! \&quot;\n&quot;, &quot;\n&quot;, &quot;- toc:true- branch: master\n&quot;, &quot;- badges: true\n&quot;, &quot;- comments: true\n&quot;, &quot;- author: In Chan\n&quot;, &quot;- categories: [jupyter, deep learning]&quot; ] }, { &quot;cell_type&quot;: &quot;code&quot;, &quot;execution_count&quot;: 1, &quot;id&quot;: &quot;e7a146d9&quot;, &quot;metadata&quot;: {}, &quot;outputs&quot;: [], &quot;source&quot;: [ &quot;from torch.utils.data import random_split\n&quot;, &quot;import torch\n&quot;, &quot;# import Engine\n&quot;, &quot;from utils import *\n&quot;, &quot;import utils\n&quot;, &quot;import math\n&quot;, &quot;from torch.autograd import Function\n&quot;, &quot;import os\n&quot;, &quot;from torch.utils.tensorboard import SummaryWriter\n&quot;, &quot;from model import Extractor, Classifier\n&quot;, &quot;from Engine import Engine\n&quot;, &quot;import time\n&quot;, &quot;import optuna\n&quot; ] }, { &quot;cell_type&quot;: &quot;code&quot;, &quot;execution_count&quot;: 3, &quot;id&quot;: &quot;8035a85c&quot;, &quot;metadata&quot;: {}, &quot;outputs&quot;: [], &quot;source&quot;: [ &quot;def define_model(trial):\n&quot;, &quot; # We optimize the number of layers, hidden units and dropout ratio in each layer.\n&quot;, &quot; log, logclose = create_logger(log_filename=log_filename,display=False)\n&quot;, &quot; log(f'Trial Number = {trial.number}')\n&quot;, &quot; n_layers = trial.suggest_int(\&quot;n_layers\&quot;, 1, 5)\n&quot;, &quot;\n&quot;, &quot; layers = []\n&quot;, &quot;\n&quot;, &quot; in_ch = 2\n&quot;, &quot; in_size=66\n&quot;, &quot; Activation_name_generator = trial.suggest_categorical(\&quot;Activate Function for Generator\&quot;, [\&quot;ReLU\&quot;, \&quot;LeakyReLU\&quot;, \&quot;ELU\&quot;,\&quot;Tanh\&quot;])\n&quot;, &quot; Activation_generator = getattr(nn, Activation_name_generator)\n&quot;, &quot; \n&quot;, &quot; for i in range(5):\n&quot;, &quot; out_ch = [int(96),int(256),int(384),int(384),int(256)]\n&quot;, &quot; padding= trial.suggest_int(\&quot;padding{}\&quot;.format(i), 0, 5)\n&quot;, &quot; kernel= trial.suggest_int(\&quot;kernel{}\&quot;.format(i), 1, 6)\n&quot;, &quot; stride= trial.suggest_int(\&quot;stride{}\&quot;.format(i), 1, 5)\n&quot;, &quot; Max_stride = trial.suggest_int(\&quot;Max_stride{}\&quot;.format(i), low=1, high=2)\n&quot;, &quot; # Dilation = trial.suggest_int(\&quot;Dilation{}\&quot;.format(i),1, 3)\n&quot;, &quot;\n&quot;, &quot; layers.append(nn.Conv1d(in_ch, out_ch[i], kernel, stride, padding))\n&quot;, &quot; layers.append(nn.BatchNorm1d(out_ch[i]))\n&quot;, &quot; layers.append(Activation_generator())\n&quot;, &quot; if i==1 or 2 or 5 :\n&quot;, &quot; layers.append(nn.MaxPool1d(2,Max_stride))\n&quot;, &quot; \n&quot;, &quot; in_ch=out_ch[i]\n&quot;, &quot;\n&quot;, &quot; in_size=((in_size-kernel+2*padding)/stride +1)\n&quot;, &quot; # in_size=((in_size+2*padding-Dilation*(kernel-1))/stride +1)\n&quot;, &quot;\n&quot;, &quot; if in_size.__class__ == float :\n&quot;, &quot; in_size = float(math.floor(in_size))\n&quot;, &quot; \n&quot;, &quot; if i == 1 or 2 or 5 : \n&quot;, &quot; if Max_stride == 2 : \n&quot;, &quot; in_size=(in_size-2)/2+1\n&quot;, &quot; if in_size.__class__ == float :\n&quot;, &quot; in_size = float(math.floor(in_size))\n&quot;, &quot; if Max_stride == 1 : \n&quot;, &quot; in_size=(in_size-2)+1\n&quot;, &quot; if in_size.__class__ == float :\n&quot;, &quot; in_size = float(math.floor(in_size))\n&quot;, &quot;\n&quot;, &quot; \n&quot;, &quot; if in_size Best_Accuracy_10 : \n&quot;, &quot; Best_Accuracy_10 = max(ACC1_10,ACC2_10)\n&quot;, &quot; log(f'--------------------------------Best Accuracy_10 = {Best_Accuracy_10 * 100}--------------------------------')\n&quot;, &quot; ACC_10 = [ACC1_10,ACC2_10]\n&quot;, &quot; ACC_30 = [ACC1_30,ACC2_30]\n&quot;, &quot; index = ACC_10.index(Best_Accuracy_10)\n&quot;, &quot; Best_Accuracy_30 = ACC_30[index]\n&quot;, &quot; log(f'--------------------------------Best Accuracy_30 = {Best_Accuracy_30 * 100}--------------------------------')\n&quot;, &quot;\n&quot;, &quot; logclose()\n&quot;, &quot; trial.report(Best_Accuracy_10,Best_Accuracy_30, epoch)\n&quot;, &quot; # Handle pruning based on the intermediate value.\n&quot;, &quot; if trial.should_prune():\n&quot;, &quot; raise optuna.exceptions.TrialPruned()\n&quot;, &quot;################################################################\n&quot;, &quot; return Best_Accuracy_10,Best_Accuracy_30&quot; ] }, { &quot;cell_type&quot;: &quot;code&quot;, &quot;execution_count&quot;: 7, &quot;id&quot;: &quot;793ee1ca&quot;, &quot;metadata&quot;: {}, &quot;outputs&quot;: [ { &quot;ename&quot;: &quot;ValueError&quot;, &quot;evalue&quot;: &quot;Please set either 'minimize' or 'maximize' to direction. You can also set the corresponding `StudyDirection` member.&quot;, &quot;output_type&quot;: &quot;error&quot;, &quot;traceback&quot;: [ &quot;\u001b[1;31m---------------------------------------------------------------------------\u001b[0m&quot;, &quot;\u001b[1;31mValueError\u001b[0m Traceback (most recent call last)&quot;, &quot;\u001b[1;32m\u001b[0m in \u001b[0;36m\u001b[1;34m\u001b[0m\n\u001b[0;32m 26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 27\u001b[0m \u001b[1;31m# study = optuna.create_study(direction=[\&quot;maximize\&quot;,\&quot;maximize\&quot;],sampler=optuna.samplers.TPESampler())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 28\u001b[1;33m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\&quot;maximize\&quot;\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\&quot;maximize\&quot;\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 29\u001b[0m \u001b[1;31m# study = optuna.create_study(direction=\&quot;maximize\&quot;,sampler=optuna.samplers.TPESampler())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 30\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n&quot;, &quot;\u001b[1;32m~\\anaconda3\\envs\\deep-learning-20\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36mcreate_study\u001b[1;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[0;32m 1127\u001b[0m ):\n\u001b[0;32m 1128\u001b[0m raise ValueError(\n\u001b[1;32m-&gt; 1129\u001b[1;33m \u001b[1;34m\&quot;Please set either 'minimize' or 'maximize' to direction. You can also set the \&quot;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 1130\u001b[0m \u001b[1;34m\&quot;corresponding `StudyDirection` member.\&quot;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 1131\u001b[0m )\n&quot;, &quot;\u001b[1;31mValueError\u001b[0m: Please set either 'minimize' or 'maximize' to direction. You can also set the corresponding `StudyDirection` member.&quot; ] } ], &quot;source&quot;: [ &quot;name = time.asctime(time.localtime(time.time()))\n&quot;, &quot;name = name.replace(' ','_').replace(':','_')\n&quot;, &quot;log_dir = f'./log/{name}'\n&quot;, &quot;os.makedirs(log_dir, exist_ok=True)\n&quot;, &quot;log_filename = os.path.join(log_dir, 'train.log')\n&quot;, &quot;\n&quot;, &quot;# Data Load\n&quot;, &quot;folds = make_folds(5)\n&quot;, &quot;S_train_data , S_train_label , _ , _ = source_Load_data(folds)\n&quot;, &quot;_ , _ , T_test_data , T_test_label = target_Load_data(folds)\n&quot;, &quot;\n&quot;, &quot;test_data_10 , test_label_10 =test_Load_data_10(folds)\n&quot;, &quot;test_data_30 , test_label_30 =test_Load_data_30(folds)\n&quot;, &quot;\n&quot;, &quot;source_set = utils.CustomDataset(data=S_train_data, label = S_train_label)\n&quot;, &quot;source_loader=DataLoader(source_set,batch_size=32,shuffle=True,drop_last=False)\n&quot;, &quot;\n&quot;, &quot;target_set = utils.CustomDataset(data=T_test_data, label = T_test_label)\n&quot;, &quot;target_loader = DataLoader(target_set,batch_size=32,shuffle=True,drop_last=False)\n&quot;, &quot;\n&quot;, &quot;test_set_10 = utils.CustomDataset(data=test_data_10, label = test_label_10)\n&quot;, &quot;test_loader_10 = DataLoader(test_set_10,batch_size=32,shuffle=True,drop_last=False)\n&quot;, &quot;\n&quot;, &quot;test_set_30 = utils.CustomDataset(data=test_data_30, label = test_label_30)\n&quot;, &quot;test_loader_30 = DataLoader(test_set_30,batch_size=32,shuffle=True,drop_last=False)\n&quot;, &quot;\n&quot;, &quot;# study = optuna.create_study(direction=[\&quot;maximize\&quot;,\&quot;maximize\&quot;],sampler=optuna.samplers.TPESampler())\n&quot;, &quot;study = optuna.create_study(direction=[\&quot;maximize\&quot;,\&quot;maximize\&quot;])\n&quot;, &quot;# study = optuna.create_study(direction=\&quot;maximize\&quot;,sampler=optuna.samplers.TPESampler())\n&quot;, &quot;study.optimize(objective, n_trials=5000)\n&quot;, &quot;\n&quot;, &quot;pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n&quot;, &quot;complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n&quot;, &quot;\n&quot;, &quot;print(\&quot;Study statistics: \&quot;)\n&quot;, &quot;print(\&quot; Number of finished trials: \&quot;, len(study.trials))\n&quot;, &quot;print(\&quot; Number of pruned trials: \&quot;, len(pruned_trials))\n&quot;, &quot;print(\&quot; Number of complete trials: \&quot;, len(complete_trials))\n&quot;, &quot;\n&quot;, &quot;print(\&quot;Best trial:\&quot;)\n&quot;, &quot;trial = study.best_trial\n&quot;, &quot;\n&quot;, &quot;print(\&quot; Value: \&quot;, trial.value)\n&quot;, &quot;\n&quot;, &quot;print(\&quot; Params: \&quot;)\n&quot;, &quot;for key, value in trial.params.items():\n&quot;, &quot; print(\&quot; {}: {}\&quot;.format(key, value))&quot; ] }, { &quot;cell_type&quot;: &quot;code&quot;, &quot;execution_count&quot;: null, &quot;id&quot;: &quot;e53f1b0e&quot;, &quot;metadata&quot;: {}, &quot;outputs&quot;: [], &quot;source&quot;: [ &quot;plot_optimization_history(study)\n&quot;, &quot;plot_intermediate_values(study)\n&quot;, &quot;plot_parallel_coordinate(study)\n&quot;, &quot;plot_parallel_coordinate(study, params=[\&quot;bagging_freq\&quot;, \&quot;bagging_fraction\&quot;])\n&quot;, &quot;plot_contour(study)\n&quot;, &quot;plot_contour(study, params=[\&quot;bagging_freq\&quot;, \&quot;bagging_fraction\&quot;])\n&quot;, &quot;plot_slice(study)\n&quot;, &quot;plot_slice(study, params=[\&quot;bagging_freq\&quot;, \&quot;bagging_fraction\&quot;])\n&quot;, &quot;plot_param_importances(study)\n&quot;, &quot;optuna.visualization.plot_param_importances(\n&quot;, &quot; study, target=lambda t: t.duration.total_seconds(), target_name=\&quot;duration\&quot;\n&quot;, &quot;)\n&quot;, &quot;plot_edf(study)&quot; ] }, { &quot;cell_type&quot;: &quot;code&quot;, &quot;execution_count&quot;: null, &quot;id&quot;: &quot;f090bc8f&quot;, &quot;metadata&quot;: {}, &quot;outputs&quot;: [], &quot;source&quot;: [] } ], &quot;metadata&quot;: { &quot;kernelspec&quot;: { &quot;display_name&quot;: &quot;Python 3&quot;, &quot;language&quot;: &quot;python&quot;, &quot;name&quot;: &quot;python3&quot; }, &quot;language_info&quot;: { &quot;codemirror_mode&quot;: { &quot;name&quot;: &quot;ipython&quot;, &quot;version&quot;: 3 }, &quot;file_extension&quot;: &quot;.py&quot;, &quot;mimetype&quot;: &quot;text/x-python&quot;, &quot;name&quot;: &quot;python&quot;, &quot;nbconvert_exporter&quot;: &quot;python&quot;, &quot;pygments_lexer&quot;: &quot;ipython3&quot;, &quot;version&quot;: &quot;3.7.10&quot; } }, &quot;nbformat&quot;: 4, &quot;nbformat_minor&quot;: 5 }</summary></entry><entry><title type="html">Title</title><link href="https://lic-deep.github.io/testcolabblog2/2020/07/04/Hyper_Parameter_Optimization.html" rel="alternate" type="text/html" title="Title" /><published>2020-07-04T00:00:00-05:00</published><updated>2020-07-04T00:00:00-05:00</updated><id>https://lic-deep.github.io/testcolabblog2/2020/07/04/Hyper_Parameter_Optimization</id><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Fastpages Notebook Blog Post</title><link href="https://lic-deep.github.io/testcolabblog2/jupyter/2020/02/20/test.html" rel="alternate" type="text/html" title="Fastpages Notebook Blog Post" /><published>2020-02-20T00:00:00-06:00</published><updated>2020-02-20T00:00:00-06:00</updated><id>https://lic-deep.github.io/testcolabblog2/jupyter/2020/02/20/test</id><author><name></name></author><category term="jupyter" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://lic-deep.github.io/testcolabblog2/images/chart-preview.png" /><media:content medium="image" url="https://lic-deep.github.io/testcolabblog2/images/chart-preview.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An Example Markdown Post</title><link href="https://lic-deep.github.io/testcolabblog2/markdown/2020/01/14/test-markdown-post.html" rel="alternate" type="text/html" title="An Example Markdown Post" /><published>2020-01-14T00:00:00-06:00</published><updated>2020-01-14T00:00:00-06:00</updated><id>https://lic-deep.github.io/testcolabblog2/markdown/2020/01/14/test-markdown-post</id><author><name></name></author><category term="markdown" /><summary type="html">Example Markdown Post</summary></entry></feed>